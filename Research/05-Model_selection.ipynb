{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening or reading PDF: no such file: '/content/resume.pdf'\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening or reading PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_skills_and_points(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    skills = []\n",
    "    key_points = []\n",
    "\n",
    "    # Define some common skills to search for\n",
    "    skill_phrases = [\n",
    "        \"machine learning\", \"deep learning\", \"data analysis\", \"python\", \"java\",\n",
    "        \"project management\", \"communication\", \"teamwork\", \"sql\", \"excel\"\n",
    "    ]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    patterns = [nlp(skill) for skill in skill_phrases]\n",
    "    matcher.add(\"SKILLS\", patterns)\n",
    "\n",
    "    # Use matcher to find skills\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        skills.append(doc[start:end].text)\n",
    "\n",
    "    # Extract key points\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.dep_ == 'ROOT':\n",
    "            key_points.append(token.text)\n",
    "\n",
    "    return skills, key_points\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path to the resume PDF file\n",
    "    pdf_path = '/content/resume.pdf'\n",
    "\n",
    "    resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    if resume_text:\n",
    "        skills, key_points = extract_skills_and_points(resume_text)\n",
    "\n",
    "        print(\"Skills:\")\n",
    "        for skill in skills:\n",
    "            print(skill)\n",
    "\n",
    "        print(\"\\nKey Points:\")\n",
    "        for point in key_points:\n",
    "            print(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using BST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_phrase = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, phrase):\n",
    "        node = self.root\n",
    "        for char in phrase:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_phrase = True\n",
    "\n",
    "    def search(self, text):\n",
    "        node = self.root\n",
    "        matched_phrases = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            char = text[i]\n",
    "            if char in node.children:\n",
    "                temp_node = node\n",
    "                temp_phrase = ''\n",
    "                while i < len(text) and char in temp_node.children:\n",
    "                    temp_phrase += char\n",
    "                    temp_node = temp_node.children[char]\n",
    "                    if temp_node.is_end_of_phrase:\n",
    "                        matched_phrases.append(temp_phrase)\n",
    "                    i += 1\n",
    "                    if i < len(text):\n",
    "                        char = text[i]\n",
    "                i -= len(temp_phrase) - 1\n",
    "            i += 1\n",
    "        return matched_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   skills  \\\n",
      "0       Construction project management Building codes...   \n",
      "1       Procurement processes Purchase order managemen...   \n",
      "2       Proficiency in HTML, CSS, and JavaScript Exper...   \n",
      "3       Marketing analytics Data analysis Data visuali...   \n",
      "4       Accounting principles Financial reporting Team...   \n",
      "...                                                   ...   \n",
      "698401  Pediatric specialization Advanced pediatric ca...   \n",
      "698402  Data analysis Database querying and reporting ...   \n",
      "698403  User-centered design principles UX/UI design t...   \n",
      "698404  Content creation (e.g., writing, editing, grap...   \n",
      "698405  Content creation (e.g., writing, editing, grap...   \n",
      "\n",
      "                                           cleaned_skills  \n",
      "0       [Construction, project, management, Building, ...  \n",
      "1       [Procurement, processes, Purchase, order, mana...  \n",
      "2       [Proficiency, HTML, CSS, JavaScript, Experienc...  \n",
      "3       [Marketing, analytics, Data, analysis, Data, v...  \n",
      "4       [Accounting, principles, Financial, reporting,...  \n",
      "...                                                   ...  \n",
      "698401  [Pediatric, specialization, Advanced, pediatri...  \n",
      "698402  [Data, analysis, Database, querying, reporting...  \n",
      "698403  [User-centered, design, principles, UX/UI, des...  \n",
      "698404  [Content, creation, Content, marketing, Social...  \n",
      "698405  [Content, creation, Content, marketing, Social...  \n",
      "\n",
      "[698406 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"Data/job_descriptions.csv\")\n",
    "\n",
    "irrelevant_words = [\n",
    "    \"knowledge\", \"and\", \"skills\", \"control\", \"including\"\n",
    "    \"codes\", \"regulations\", \"cost\", \"monitor\", \"timelines\",\n",
    "    \"assist\", \"in\", \"budgeting\"\n",
    "]\n",
    "\n",
    "# Function to clean and extract skills\n",
    "pattern = re.compile(r'\\b(?:' + '|'.join(irrelevant_words) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Function to clean and extract skills\n",
    "def clean_skills(skills_string):\n",
    "    # Remove brackets and their contents\n",
    "    skills_string = re.sub(r'\\[.*?\\]|\\(.*?\\)|\\{.*?\\}', '', skills_string)\n",
    "    \n",
    "    # Clean the skills string by removing irrelevant words\n",
    "    cleaned_skills = pattern.sub('', skills_string)\n",
    "    \n",
    "    # Split the cleaned string into a list of skills\n",
    "    skill_list = re.split(r'\\s*,\\s*|\\s+', cleaned_skills.strip())\n",
    "    \n",
    "    # Remove any empty strings from the list\n",
    "    skill_list = [skill for skill in skill_list if skill]\n",
    "    \n",
    "    return skill_list\n",
    "\n",
    "# Apply the function to the 'skills' column and generate the list of cleaned skills\n",
    "df['cleaned_skills'] = df['skills'].apply(clean_skills)\n",
    "\n",
    "# Print the DataFrame to see the results\n",
    "print(df[['skills', 'cleaned_skills']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening or reading PDF: no such file: '/content/resume.pdf'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage of Trie in the main script\n",
    "def extract_skills_and_points(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    skills = []\n",
    "    key_points = []\n",
    "\n",
    "    # Define some common skills to search for\n",
    "    skill_phrases = [\n",
    "        \"machine learning\", \"deep learning\", \"data analysis\", \"python\", \"java\",\n",
    "        \"project management\", \"communication\", \"teamwork\", \"sql\", \"excel\"\n",
    "    ]\n",
    "\n",
    "    # Build the trie\n",
    "    trie = Trie()\n",
    "    for phrase in skill_phrases:\n",
    "        trie.insert(phrase.lower())\n",
    "\n",
    "    # Use trie to find skills\n",
    "    lower_text = text.lower()\n",
    "    skills = trie.search(lower_text)\n",
    "\n",
    "    # Extract key points\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.dep_ == 'ROOT':\n",
    "            key_points.append(token.text)\n",
    "\n",
    "    return skills, key_points\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path to the resume PDF file\n",
    "    pdf_path = '/content/resume.pdf'\n",
    "\n",
    "    resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    if resume_text:\n",
    "        skills, key_points = extract_skills_and_points(resume_text)\n",
    "\n",
    "        print(\"Skills:\")\n",
    "        for skill in skills:\n",
    "            print(skill)\n",
    "\n",
    "        print(\"\\nKey Points:\")\n",
    "        for point in key_points:\n",
    "            print(point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/data_after_feature_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UX/UI Designer</th>\n",
       "      <td>20907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Marketing Specialist</th>\n",
       "      <td>11970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineer</th>\n",
       "      <td>11912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Engineer</th>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Tester</th>\n",
       "      <td>9087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Procurement Coordinator</th>\n",
       "      <td>1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Assistant</th>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Planner</th>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supply Chain Analyst</th>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inventory Analyst</th>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count\n",
       "Job Title                          \n",
       "UX/UI Designer                20907\n",
       "Digital Marketing Specialist  11970\n",
       "Software Engineer             11912\n",
       "Network Engineer              10500\n",
       "Software Tester                9087\n",
       "...                             ...\n",
       "Procurement Coordinator        1468\n",
       "Personal Assistant             1461\n",
       "Financial Planner              1455\n",
       "Supply Chain Analyst           1439\n",
       "Inventory Analyst              1406\n",
       "\n",
       "[147 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset[\"Job Title\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"Job Title\"])\n",
    "y = dataset[\"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'UX/UI Designer': 18793, 'Digital Marketing Specialist': 10735, 'Software Engineer': 10692, 'Network Engineer': 9467, 'Software Tester': 8206, 'Executive Assistant': 8113, 'Procurement Manager': 8038, 'Financial Advisor': 8005, 'Social Media Manager': 6910, 'Sales Representative': 6857, 'Network Administrator': 6819, 'Data Analyst': 6795, 'Purchasing Agent': 6769, 'Administrative Assistant': 6751, 'Event Planner': 6714, 'Systems Administrator': 6700, 'Procurement Specialist': 6694, 'Customer Support Specialist': 6660, 'HR Coordinator': 6629, 'Customer Success Manager': 5519, 'UI Developer': 5470, 'Legal Assistant': 5470, 'Marketing Analyst': 5429, 'Landscape Architect': 5420, 'Graphic Designer': 5414, 'Content Writer': 5408, 'Supply Chain Manager': 5400, 'Account Manager': 5394, 'Project Manager': 5391, 'Marketing Manager': 5391, 'Investment Banker': 5386, 'Event Coordinator': 5378, 'Operations Manager': 5375, 'Litigation Attorney': 5355, 'Research Analyst': 5347, 'Mechanical Engineer': 5343, 'Architect': 5339, 'Project Coordinator': 5295, 'Civil Engineer': 5229, 'Brand Ambassador': 4158, 'Teacher': 4157, 'Physician Assistant': 4148, 'Public Relations Specialist': 4129, 'Veterinarian': 4120, 'Nurse Practitioner': 4110, 'Marketing Specialist': 4109, 'Brand Manager': 4106, 'Pediatrician': 4100, 'Legal Advisor': 4098, 'Accountant': 4097, 'Customer Service Manager': 4097, 'Substance Abuse Counselor': 4094, 'Occupational Therapist': 4089, 'Quality Assurance Analyst': 4089, 'SEO Specialist': 4086, 'Investment Analyst': 4082, 'Chemical Analyst': 4081, 'Art Teacher': 4078, 'Aerospace Engineer': 4077, 'Chemical Engineer': 4075, 'Marketing Coordinator': 4071, 'Physical Therapist': 4069, 'Electrical Designer': 4067, 'Paralegal': 4065, 'Dental Hygienist': 4062, 'Network Security Specialist': 4061, 'Speech Therapist': 4057, 'Database Administrator': 4055, 'IT Support Specialist': 4053, 'Human Resources Manager': 4048, 'Electrical Engineer': 4047, 'HR Manager': 4044, 'Account Executive': 4044, 'Finance Manager': 4040, 'Java Developer': 4039, 'Technical Writer': 4038, 'Urban Planner': 4034, 'Art Director': 4030, 'Sales Manager': 4025, 'Mechanical Designer': 4024, 'QA Analyst': 4022, 'Tax Consultant': 4022, 'Social Worker': 4013, 'Email Marketing Specialist': 4012, 'UX Researcher': 4009, 'Legal Counsel': 4005, 'Software Architect': 4002, 'Psychologist': 4001, 'Registered Nurse': 4000, 'Market Research Analyst': 3998, 'Nurse Manager': 3994, 'Front-End Developer': 3991, 'Pharmaceutical Sales Representative': 3987, 'Interior Designer': 3986, 'Office Manager': 3982, 'Data Engineer': 3980, 'Marketing Director': 3976, 'Web Developer': 3975, 'Research Scientist': 3967, 'Business Development Manager': 3965, 'Family Nurse Practitioner': 3964, 'Environmental Consultant': 3952, 'Financial Analyst': 3950, 'Sales Consultant': 3942, 'Structural Engineer': 3929, 'SEM Specialist': 3920, 'Copywriter': 3919, 'Business Analyst': 3907, 'Data Entry Clerk': 2822, 'IT Manager': 2780, 'Front-End Engineer': 2763, 'Customer Service Representative': 2751, 'Web Designer': 2750, 'Account Director': 2744, 'Back-End Developer': 2730, 'Database Developer': 2724, 'Systems Analyst': 2719, 'Legal Secretary': 2716, 'Social Media Coordinator': 2713, 'Process Engineer': 2710, 'Network Technician': 2708, 'SEO Analyst': 2700, 'Systems Engineer': 2699, 'Family Lawyer': 2696, 'Landscape Designer': 2687, 'Data Scientist': 2682, 'Wedding Planner': 2660, 'Product Manager': 2658, 'Architectural Designer': 2648, 'Financial Controller': 2646, 'Environmental Engineer': 2626, 'QA Engineer': 1395, 'Sales Associate': 1395, 'Market Analyst': 1388, 'Software Developer': 1369, 'Event Manager': 1359, 'Key Account Manager': 1359, 'IT Administrator': 1359, 'Investment Advisor': 1356, 'Product Designer': 1339, 'Procurement Coordinator': 1331, 'HR Generalist': 1329, 'Network Analyst': 1326, 'Personal Assistant': 1298, 'Financial Planner': 1295, 'Inventory Analyst': 1285, 'Supply Chain Analyst': 1272})\n",
      "Resampled dataset shape: Counter({'Network Engineer': 18793, 'Dental Hygienist': 18793, 'Finance Manager': 18793, 'Network Administrator': 18793, 'Financial Advisor': 18793, 'Business Analyst': 18793, 'UX/UI Designer': 18793, 'Veterinarian': 18793, 'UI Developer': 18793, 'Executive Assistant': 18793, 'HR Manager': 18793, 'Pediatrician': 18793, 'Electrical Engineer': 18793, 'Pharmaceutical Sales Representative': 18793, 'Electrical Designer': 18793, 'Customer Success Manager': 18793, 'Urban Planner': 18793, 'Email Marketing Specialist': 18793, 'Landscape Architect': 18793, 'Data Entry Clerk': 18793, 'Interior Designer': 18793, 'Environmental Engineer': 18793, 'Financial Planner': 18793, 'Marketing Analyst': 18793, 'Process Engineer': 18793, 'Environmental Consultant': 18793, 'Database Administrator': 18793, 'Legal Secretary': 18793, 'Data Analyst': 18793, 'Substance Abuse Counselor': 18793, 'Digital Marketing Specialist': 18793, 'Teacher': 18793, 'Data Scientist': 18793, 'Copywriter': 18793, 'Legal Advisor': 18793, 'Web Developer': 18793, 'Marketing Coordinator': 18793, 'Civil Engineer': 18793, 'Graphic Designer': 18793, 'Legal Counsel': 18793, 'QA Analyst': 18793, 'Procurement Manager': 18793, 'Nurse Practitioner': 18793, 'Event Planner': 18793, 'Systems Administrator': 18793, 'Social Worker': 18793, 'Speech Therapist': 18793, 'Human Resources Manager': 18793, 'Structural Engineer': 18793, 'Operations Manager': 18793, 'Network Analyst': 18793, 'Personal Assistant': 18793, 'Administrative Assistant': 18793, 'Customer Support Specialist': 18793, 'Financial Analyst': 18793, 'Procurement Specialist': 18793, 'Software Engineer': 18793, 'Event Coordinator': 18793, 'SEM Specialist': 18793, 'Brand Ambassador': 18793, 'Software Tester': 18793, 'Customer Service Representative': 18793, 'Technical Writer': 18793, 'IT Manager': 18793, 'Investment Banker': 18793, 'Art Teacher': 18793, 'Data Engineer': 18793, 'Mechanical Designer': 18793, 'Psychologist': 18793, 'Family Nurse Practitioner': 18793, 'SEO Specialist': 18793, 'Chemical Analyst': 18793, 'Network Security Specialist': 18793, 'Accountant': 18793, 'Project Manager': 18793, 'Social Media Coordinator': 18793, 'Product Designer': 18793, 'Financial Controller': 18793, 'Project Coordinator': 18793, 'Physical Therapist': 18793, 'HR Coordinator': 18793, 'Sales Representative': 18793, 'Account Manager': 18793, 'Nurse Manager': 18793, 'Java Developer': 18793, 'Web Designer': 18793, 'Landscape Designer': 18793, 'Public Relations Specialist': 18793, 'Occupational Therapist': 18793, 'Art Director': 18793, 'Aerospace Engineer': 18793, 'Investment Analyst': 18793, 'Litigation Attorney': 18793, 'Account Executive': 18793, 'Supply Chain Manager': 18793, 'Mechanical Engineer': 18793, 'Event Manager': 18793, 'Purchasing Agent': 18793, 'Social Media Manager': 18793, 'Back-End Developer': 18793, 'Key Account Manager': 18793, 'Marketing Manager': 18793, 'Sales Manager': 18793, 'Software Architect': 18793, 'Brand Manager': 18793, 'Office Manager': 18793, 'Front-End Developer': 18793, 'Marketing Specialist': 18793, 'Content Writer': 18793, 'Supply Chain Analyst': 18793, 'Sales Consultant': 18793, 'Registered Nurse': 18793, 'Research Analyst': 18793, 'Tax Consultant': 18793, 'Market Research Analyst': 18793, 'Chemical Engineer': 18793, 'Legal Assistant': 18793, 'UX Researcher': 18793, 'Research Scientist': 18793, 'Architect': 18793, 'Family Lawyer': 18793, 'Paralegal': 18793, 'Wedding Planner': 18793, 'Marketing Director': 18793, 'Quality Assurance Analyst': 18793, 'Database Developer': 18793, 'SEO Analyst': 18793, 'IT Support Specialist': 18793, 'Front-End Engineer': 18793, 'Procurement Coordinator': 18793, 'Business Development Manager': 18793, 'HR Generalist': 18793, 'Investment Advisor': 18793, 'Architectural Designer': 18793, 'Inventory Analyst': 18793, 'Account Director': 18793, 'QA Engineer': 18793, 'Customer Service Manager': 18793, 'Software Developer': 18793, 'Sales Associate': 18793, 'Systems Engineer': 18793, 'Network Technician': 18793, 'Physician Assistant': 18793, 'Product Manager': 18793, 'Systems Analyst': 18793, 'Market Analyst': 18793, 'IT Administrator': 18793})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
    "print(f\"Resampled dataset shape: {Counter(y_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_resampled.copy() \n",
    "y = y_train_resampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2762571, 67), (2762571,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2486313, 67), (276258, 67), (2486313,), (276258,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2486313, 67), (276258, 67), (2486313, 147), (276258, 147))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=0.01,  # Starting learning rate\n",
    "    decay_steps=100,            # Number of steps before applying decay\n",
    "    decay_rate=0.96,             # Decay rate\n",
    "    staircase=True               # Whether to apply decay at discrete steps\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  8704      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  132096    \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  1049600   \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  2107400   \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  4229192   \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8878971 (33.87 MB)\n",
      "Trainable params: 8878971 (33.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.dense3 = Dense(1024, activation='relu')\n",
    "        self.dense4 = Dense(1024, activation='relu')\n",
    "        self.dense5 = Dense(2056, activation='relu')\n",
    "        self.dense6 = Dense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim = input_dim, num_classes = num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer , loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "972/972 [==============================] - 190s 194ms/step - loss: 4430.4092 - accuracy: 0.0068 - val_loss: 4.9909 - val_accuracy: 0.0066\n",
      "Epoch 2/2\n",
      "972/972 [==============================] - 178s 184ms/step - loss: 4.9909 - accuracy: 0.0068 - val_loss: 4.9908 - val_accuracy: 0.0067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2481698d750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, validation_split=0.2, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobRecommendationSystem:\n",
    "    def __init__(self, data, cat_features, num_features, target_var):\n",
    "        self.data = data\n",
    "        self.cat_features = cat_features\n",
    "        self.num_features = num_features\n",
    "        self.target_var = target_var\n",
    "        self.encoder = OneHotEncoder(sparse = False)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.job_title_encoder = OneHotEncoder(sparse = False)\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        # Encode categorical features\n",
    "        encoded_features = self.encoder.fit_transform(self.data[self.cat_features])\n",
    "        encoded_df = pd.DataFrame(encoded_features, columns = self.encoder.get_feature_names_out())\n",
    "        \n",
    "        # Normalize numerical features\n",
    "        numerical_features = self.scaler.fit_transform(self.data[self.num_features])\n",
    "        numerical_df = pd.DataFrame(numerical_features, columns = self.num_features)\n",
    "        \n",
    "        # Flatten the skills list and encode\n",
    "        # The skills column must be list of list\n",
    "        all_skills = list(set(skill for sublist in self.data[\"skills\"] for skill in sublist))\n",
    "        skills_df = pd.DataFrame([[skill in sublist for skill in all_skills] for sublist in self.data[\"skills\"]], columns = all_skills)\n",
    "        \n",
    "        # Combine all features\n",
    "        self.X = pd.concat([encoded_df, numerical_df, skills_df], axis = 1)\n",
    "        \n",
    "        # Encode the Job Title\n",
    "        self.y = self.job_title_encoder.fit_transform(self.data[self.target_var])\n",
    "        \n",
    "        # Split the data into training and test sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define the neural network model using the Functional API\n",
    "        input_layer = Input(shape = (self.X_train.shape[1],))\n",
    "        dense_layer_1 = Dense(64, activation = \"relu\")(input_layer)\n",
    "        dense_layer_2 = Dense(32, activation = \"relu\")(dense_layer_1)\n",
    "        output_layer = Dense(self.y.shape[1], activation = \"softmax\")(dense_layer_2)\n",
    "        \n",
    "        self.model = Model(inputs = input_layer, outputs = output_layer)\n",
    "        self.model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    def train_model(self, epochs = 10, batch_size = 10):\n",
    "        self.model.fit(self.X_train, self.y_train, epochs = epochs, batch_size = batch_size, validation_split = 0.2)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        loss, accuracy = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "    \n",
    "    def make_predictions(self):\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "        predicted_classes = self.job_title_encoder.inverse_transform(predictions)\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/data_after_feature_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"Job Title\"])\n",
    "y = dataset[\"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((626410, 67), (69602, 67), (626410,), (69602,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadDense(Layer):\n",
    "\n",
    "  def __init__(self, units = 32, activation = None):\n",
    "    super(QuadDense, self).__init__()\n",
    "    self.units = units\n",
    "    self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    a_init = tf.random_normal_initializer()\n",
    "    b_init = tf.random_normal_initializer()\n",
    "    c_init = tf.zeros_initializer()\n",
    "\n",
    "    self.a = tf.Variable(initial_value = a_init(shape = (input_shape[-1], self.units),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"kernel\")\n",
    "\n",
    "    self.b = tf.Variable(initial_value = b_init(shape = (input_shape[-1], self.units),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"kernel\")\n",
    "\n",
    "    self.c = tf.Variable(initial_value = c_init(shape = (self.units, ),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"bias\")\n",
    "\n",
    "  def call(self, inputs):\n",
    "    result = tf.matmul(tf.math.square(inputs), self.a) + tf.matmul(inputs, self.b) + self.c\n",
    "\n",
    "    return self.activation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=0.01,  # Starting learning rate\n",
    "    decay_steps=1000,            # Number of steps before applying decay\n",
    "    decay_rate=0.96,             # Decay rate\n",
    "    staircase=True               # Whether to apply decay at discrete steps\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             multiple                  8704      \n",
      "                                                                 \n",
      " dense_8 (Dense)             multiple                  33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  131584    \n",
      "                                                                 \n",
      " quad_dense (QuadDense)      multiple                  2107400   \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2583091 (9.85 MB)\n",
      "Trainable params: 2583091 (9.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(256, activation='relu')\n",
    "        self.dense3 = Dense(512, activation='relu')\n",
    "        self.dense4 = QuadDense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim = input_dim, num_classes = num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3916/3916 [==============================] - 50s 13ms/step - loss: 4.8856 - accuracy: 0.0300 - val_loss: 4.8853 - val_accuracy: 0.0299\n",
      "Epoch 2/5\n",
      "3916/3916 [==============================] - 49s 12ms/step - loss: 4.8848 - accuracy: 0.0300 - val_loss: 4.8849 - val_accuracy: 0.0299\n",
      "Epoch 3/5\n",
      "3916/3916 [==============================] - 48s 12ms/step - loss: 4.8844 - accuracy: 0.0300 - val_loss: 4.8849 - val_accuracy: 0.0299\n",
      "Epoch 4/5\n",
      "3916/3916 [==============================] - 48s 12ms/step - loss: 4.8842 - accuracy: 0.0300 - val_loss: 4.8844 - val_accuracy: 0.0299\n",
      "Epoch 5/5\n",
      "3916/3916 [==============================] - 48s 12ms/step - loss: 4.8841 - accuracy: 0.0300 - val_loss: 4.8843 - val_accuracy: 0.0299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24828f83d90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Create an Adam optimizer with a custom learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             multiple                  256       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  24704     \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  1097856   \n",
      "                                                                 \n",
      " batch_normalization (Batch  multiple                  512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  132096    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  multiple                  4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " attention (Attention)       multiple                  0         \n",
      "                                                                 \n",
      " attention_1 (Attention)     multiple                  0         \n",
      "                                                                 \n",
      " quad_dense_1 (QuadDense)    multiple                  2098176   \n",
      "                                                                 \n",
      " quad_dense_2 (QuadDense)    multiple                  2098176   \n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  2107400   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  multiple                  8224      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            multiple                  4229192   \n",
      "                                                                 \n",
      " dense_15 (Dense)            multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12103067 (46.17 MB)\n",
      "Trainable params: 12096651 (46.15 MB)\n",
      "Non-trainable params: 6416 (25.06 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Conv1D, Flatten, BatchNormalization, Dropout, Attention, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a custom layer QuadDense\n",
    "class QuadDense(Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super(QuadDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        a_init = tf.random_normal_initializer()\n",
    "        b_init = tf.random_normal_initializer()\n",
    "        c_init = tf.zeros_initializer()\n",
    "\n",
    "        self.a = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=a_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"a\")\n",
    "\n",
    "        self.b = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=b_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"b\")\n",
    "\n",
    "        self.c = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=c_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"c\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        result = tf.matmul(tf.math.square(inputs), self.a) + tf.matmul(inputs, self.b) + self.c\n",
    "        return self.activation(result)\n",
    "\n",
    "# Define a model that uses various layers for better performance\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv1D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = Conv1D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.2)\n",
    "        \n",
    "        # Adding attention layers\n",
    "        self.attention1 = Attention()\n",
    "        self.attention2 = Attention()\n",
    "        \n",
    "        self.dense3 = QuadDense(1024, activation='relu')\n",
    "        self.dense4 = QuadDense(1024, activation='relu')\n",
    "        self.dense5 = Dense(2056, activation='relu')\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.2)\n",
    "        self.dense6 = Dense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(tf.expand_dims(inputs, axis=-1))  # Expanding dims to use Conv1D\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Applying attention\n",
    "        query = tf.expand_dims(x, axis=1)  # Adding sequence dimension for Attention layer\n",
    "        attention_output1 = self.attention1([query, query])\n",
    "        x = Add()([x, tf.squeeze(attention_output1, axis=1)])\n",
    "        \n",
    "        attention_output2 = self.attention2([query, query])\n",
    "        x = Add()([x, tf.squeeze(attention_output2, axis=1)])\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "245/245 [==============================] - 111s 452ms/step - loss: 4.8956 - accuracy: 0.0298 - val_loss: 16.6723 - val_accuracy: 0.0143\n",
      "Epoch 2/5\n",
      "245/245 [==============================] - 110s 447ms/step - loss: 4.9035 - accuracy: 0.0295 - val_loss: 4.9112 - val_accuracy: 0.0299\n",
      "Epoch 3/5\n",
      "245/245 [==============================] - 109s 445ms/step - loss: 4.8940 - accuracy: 0.0299 - val_loss: 4.8905 - val_accuracy: 0.0297\n",
      "Epoch 4/5\n",
      "245/245 [==============================] - 107s 437ms/step - loss: 4.8915 - accuracy: 0.0299 - val_loss: 4.8904 - val_accuracy: 0.0297\n",
      "Epoch 5/5\n",
      "245/245 [==============================] - 107s 437ms/step - loss: 4.8902 - accuracy: 0.0299 - val_loss: 4.8894 - val_accuracy: 0.0298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24838bafe10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176/2176 [==============================] - 12s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176/2176 [==============================] - 13s 6ms/step - loss: 4.8867 - accuracy: 0.0303\n",
      "Test Loss: 4.886653900146484\n",
      "Test Accuracy: 0.030329588800668716\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   True Labels  Predicted Labels\n",
      "0           40               141\n",
      "1           94               141\n",
      "2           62               141\n",
      "3           90               141\n",
      "4           35               141\n"
     ]
    }
   ],
   "source": [
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Assuming X_test is a 2D array where each row is a sample\n",
    "# Convert X_test to a DataFrame if it's not already\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "# Create a DataFrame to hold original values, true labels, and predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'True Labels': y_test_classes,\n",
    "    'Predicted Labels': predicted_classes\n",
    "})\n",
    "\n",
    "print(results_df.head())  # Display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([141,   2, 126], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[\"Predicted Labels\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename where you want to save the model\n",
    "filename = 'Data/model.pkl'\n",
    "\n",
    "# Open a file in write-binary mode and use pickle.dump to save the model\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Model:\n",
    "    def __init__(self, input_dim, hidden_layers, output_dim):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        input_dim (int): Number of the input features\n",
    "        hidden_layers (list): list of the number of units in the hidden layer\n",
    "        output_dim: nNumber of the output units \n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        self.model.add(Dense(hidden_layers[0], input_dim = input_dim, activation = \"relu\"))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for units in hidden_layers[1:]:\n",
    "            self.model.add(Dense(units, activation = \"relu\"))\n",
    "        \n",
    "        # Output layer\n",
    "        self.model.add(Dense(output_dim, activation = \"linear\"))\n",
    "        \n",
    "        # Compile the model\n",
    "        self.model.compile(optimizer = \"adam\", loss = \"mse\", metrics = [\"mse\"])\n",
    "    \n",
    "    def train(self, X_train, y_train, epochs = 10, batch_size = 32):\n",
    "        self.model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
