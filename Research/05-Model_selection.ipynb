{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening or reading PDF: no such file: '/content/resume.pdf'\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening or reading PDF: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_skills_and_points(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    skills = []\n",
    "    key_points = []\n",
    "\n",
    "    # Define some common skills to search for\n",
    "    skill_phrases = [\n",
    "        \"machine learning\", \"deep learning\", \"data analysis\", \"python\", \"java\",\n",
    "        \"project management\", \"communication\", \"teamwork\", \"sql\", \"excel\"\n",
    "    ]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    patterns = [nlp(skill) for skill in skill_phrases]\n",
    "    matcher.add(\"SKILLS\", patterns)\n",
    "\n",
    "    # Use matcher to find skills\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        skills.append(doc[start:end].text)\n",
    "\n",
    "    # Extract key points\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.dep_ == 'ROOT':\n",
    "            key_points.append(token.text)\n",
    "\n",
    "    return skills, key_points\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path to the resume PDF file\n",
    "    pdf_path = '/content/resume.pdf'\n",
    "\n",
    "    resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    if resume_text:\n",
    "        skills, key_points = extract_skills_and_points(resume_text)\n",
    "\n",
    "        print(\"Skills:\")\n",
    "        for skill in skills:\n",
    "            print(skill)\n",
    "\n",
    "        print(\"\\nKey Points:\")\n",
    "        for point in key_points:\n",
    "            print(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using BST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_end_of_phrase = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, phrase):\n",
    "        node = self.root\n",
    "        for char in phrase:\n",
    "            if char not in node.children:\n",
    "                node.children[char] = TrieNode()\n",
    "            node = node.children[char]\n",
    "        node.is_end_of_phrase = True\n",
    "\n",
    "    def search(self, text):\n",
    "        node = self.root\n",
    "        matched_phrases = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            char = text[i]\n",
    "            if char in node.children:\n",
    "                temp_node = node\n",
    "                temp_phrase = ''\n",
    "                while i < len(text) and char in temp_node.children:\n",
    "                    temp_phrase += char\n",
    "                    temp_node = temp_node.children[char]\n",
    "                    if temp_node.is_end_of_phrase:\n",
    "                        matched_phrases.append(temp_phrase)\n",
    "                    i += 1\n",
    "                    if i < len(text):\n",
    "                        char = text[i]\n",
    "                i -= len(temp_phrase) - 1\n",
    "            i += 1\n",
    "        return matched_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   skills  \\\n",
      "0       Construction project management Building codes...   \n",
      "1       Procurement processes Purchase order managemen...   \n",
      "2       Proficiency in HTML, CSS, and JavaScript Exper...   \n",
      "3       Marketing analytics Data analysis Data visuali...   \n",
      "4       Accounting principles Financial reporting Team...   \n",
      "...                                                   ...   \n",
      "698401  Pediatric specialization Advanced pediatric ca...   \n",
      "698402  Data analysis Database querying and reporting ...   \n",
      "698403  User-centered design principles UX/UI design t...   \n",
      "698404  Content creation (e.g., writing, editing, grap...   \n",
      "698405  Content creation (e.g., writing, editing, grap...   \n",
      "\n",
      "                                           cleaned_skills  \n",
      "0       [Construction, project, management, Building, ...  \n",
      "1       [Procurement, processes, Purchase, order, mana...  \n",
      "2       [Proficiency, HTML, CSS, JavaScript, Experienc...  \n",
      "3       [Marketing, analytics, Data, analysis, Data, v...  \n",
      "4       [Accounting, principles, Financial, reporting,...  \n",
      "...                                                   ...  \n",
      "698401  [Pediatric, specialization, Advanced, pediatri...  \n",
      "698402  [Data, analysis, Database, querying, reporting...  \n",
      "698403  [User-centered, design, principles, UX/UI, des...  \n",
      "698404  [Content, creation, Content, marketing, Social...  \n",
      "698405  [Content, creation, Content, marketing, Social...  \n",
      "\n",
      "[698406 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"Data/job_descriptions.csv\")\n",
    "\n",
    "irrelevant_words = [\n",
    "    \"knowledge\", \"and\", \"skills\", \"control\", \"including\"\n",
    "    \"codes\", \"regulations\", \"cost\", \"monitor\", \"timelines\",\n",
    "    \"assist\", \"in\", \"budgeting\"\n",
    "]\n",
    "\n",
    "# Function to clean and extract skills\n",
    "pattern = re.compile(r'\\b(?:' + '|'.join(irrelevant_words) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Function to clean and extract skills\n",
    "def clean_skills(skills_string):\n",
    "    # Remove brackets and their contents\n",
    "    skills_string = re.sub(r'\\[.*?\\]|\\(.*?\\)|\\{.*?\\}', '', skills_string)\n",
    "    \n",
    "    # Clean the skills string by removing irrelevant words\n",
    "    cleaned_skills = pattern.sub('', skills_string)\n",
    "    \n",
    "    # Split the cleaned string into a list of skills\n",
    "    skill_list = re.split(r'\\s*,\\s*|\\s+', cleaned_skills.strip())\n",
    "    \n",
    "    # Remove any empty strings from the list\n",
    "    skill_list = [skill for skill in skill_list if skill]\n",
    "    \n",
    "    return skill_list\n",
    "\n",
    "# Apply the function to the 'skills' column and generate the list of cleaned skills\n",
    "df['cleaned_skills'] = df['skills'].apply(clean_skills)\n",
    "\n",
    "# Print the DataFrame to see the results\n",
    "print(df[['skills', 'cleaned_skills']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening or reading PDF: no such file: '/content/resume.pdf'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage of Trie in the main script\n",
    "def extract_skills_and_points(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    skills = []\n",
    "    key_points = []\n",
    "\n",
    "    # Define some common skills to search for\n",
    "    skill_phrases = [\n",
    "        \"machine learning\", \"deep learning\", \"data analysis\", \"python\", \"java\",\n",
    "        \"project management\", \"communication\", \"teamwork\", \"sql\", \"excel\"\n",
    "    ]\n",
    "\n",
    "    # Build the trie\n",
    "    trie = Trie()\n",
    "    for phrase in skill_phrases:\n",
    "        trie.insert(phrase.lower())\n",
    "\n",
    "    # Use trie to find skills\n",
    "    lower_text = text.lower()\n",
    "    skills = trie.search(lower_text)\n",
    "\n",
    "    # Extract key points\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB' and token.dep_ == 'ROOT':\n",
    "            key_points.append(token.text)\n",
    "\n",
    "    return skills, key_points\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual path to the resume PDF file\n",
    "    pdf_path = '/content/resume.pdf'\n",
    "\n",
    "    resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    if resume_text:\n",
    "        skills, key_points = extract_skills_and_points(resume_text)\n",
    "\n",
    "        print(\"Skills:\")\n",
    "        for skill in skills:\n",
    "            print(skill)\n",
    "\n",
    "        print(\"\\nKey Points:\")\n",
    "        for point in key_points:\n",
    "            print(point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/data_after_feature_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UX/UI Designer</th>\n",
       "      <td>20907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Marketing Specialist</th>\n",
       "      <td>11970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineer</th>\n",
       "      <td>11912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Engineer</th>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Tester</th>\n",
       "      <td>9087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Procurement Coordinator</th>\n",
       "      <td>1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Assistant</th>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Planner</th>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supply Chain Analyst</th>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inventory Analyst</th>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count\n",
       "Job Title                          \n",
       "UX/UI Designer                20907\n",
       "Digital Marketing Specialist  11970\n",
       "Software Engineer             11912\n",
       "Network Engineer              10500\n",
       "Software Tester                9087\n",
       "...                             ...\n",
       "Procurement Coordinator        1468\n",
       "Personal Assistant             1461\n",
       "Financial Planner              1455\n",
       "Supply Chain Analyst           1439\n",
       "Inventory Analyst              1406\n",
       "\n",
       "[147 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset[\"Job Title\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"Job Title\"])\n",
    "y = dataset[\"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'UX/UI Designer': 14642, 'Digital Marketing Specialist': 8310, 'Software Engineer': 8283, 'Network Engineer': 7413, 'Software Tester': 6373, 'Procurement Manager': 6311, 'Executive Assistant': 6291, 'Financial Advisor': 6257, 'Social Media Manager': 5384, 'Sales Representative': 5341, 'Network Administrator': 5322, 'Purchasing Agent': 5309, 'Administrative Assistant': 5254, 'Data Analyst': 5242, 'Procurement Specialist': 5235, 'Systems Administrator': 5230, 'Event Planner': 5203, 'HR Coordinator': 5197, 'Customer Support Specialist': 5157, 'Customer Success Manager': 4267, 'UI Developer': 4256, 'Legal Assistant': 4251, 'Account Manager': 4232, 'Operations Manager': 4228, 'Marketing Manager': 4224, 'Graphic Designer': 4215, 'Content Writer': 4213, 'Landscape Architect': 4206, 'Litigation Attorney': 4206, 'Project Manager': 4185, 'Project Coordinator': 4180, 'Investment Banker': 4167, 'Marketing Analyst': 4159, 'Mechanical Engineer': 4151, 'Architect': 4147, 'Research Analyst': 4143, 'Event Coordinator': 4138, 'Supply Chain Manager': 4117, 'Civil Engineer': 4084, 'Legal Advisor': 3243, 'Public Relations Specialist': 3239, 'Physician Assistant': 3220, 'Quality Assurance Analyst': 3215, 'Nurse Practitioner': 3211, 'Teacher': 3206, 'SEO Specialist': 3202, 'Pediatrician': 3196, 'Chemical Analyst': 3193, 'Substance Abuse Counselor': 3193, 'Physical Therapist': 3191, 'Paralegal': 3187, 'Aerospace Engineer': 3184, 'Java Developer': 3181, 'Accountant': 3178, 'Human Resources Manager': 3177, 'Network Security Specialist': 3174, 'Legal Counsel': 3173, 'Investment Analyst': 3171, 'Dental Hygienist': 3166, 'Marketing Coordinator': 3165, 'Occupational Therapist': 3165, 'Veterinarian': 3163, 'IT Support Specialist': 3163, 'Customer Service Manager': 3163, 'Database Administrator': 3161, 'Sales Manager': 3160, 'Brand Ambassador': 3157, 'Art Teacher': 3157, 'Chemical Engineer': 3152, 'Electrical Designer': 3151, 'Speech Therapist': 3150, 'Art Director': 3149, 'Technical Writer': 3148, 'Urban Planner': 3148, 'Electrical Engineer': 3146, 'Brand Manager': 3146, 'Marketing Specialist': 3144, 'Psychologist': 3144, 'UX Researcher': 3137, 'HR Manager': 3130, 'Account Executive': 3128, 'Finance Manager': 3126, 'Email Marketing Specialist': 3126, 'Mechanical Designer': 3122, 'Nurse Manager': 3116, 'Market Research Analyst': 3110, 'Software Architect': 3110, 'Tax Consultant': 3108, 'Interior Designer': 3103, 'Social Worker': 3099, 'Research Scientist': 3098, 'Pharmaceutical Sales Representative': 3094, 'Registered Nurse': 3092, 'QA Analyst': 3087, 'Marketing Director': 3087, 'Family Nurse Practitioner': 3083, 'Data Engineer': 3083, 'Office Manager': 3080, 'Business Development Manager': 3069, 'Web Developer': 3067, 'Business Analyst': 3066, 'Environmental Consultant': 3061, 'Financial Analyst': 3060, 'Structural Engineer': 3054, 'Front-End Developer': 3048, 'Sales Consultant': 3048, 'Copywriter': 3047, 'SEM Specialist': 3005, 'Data Entry Clerk': 2183, 'Web Designer': 2153, 'Systems Analyst': 2149, 'IT Manager': 2143, 'Customer Service Representative': 2136, 'Account Director': 2134, 'Front-End Engineer': 2133, 'Social Media Coordinator': 2130, 'Systems Engineer': 2125, 'SEO Analyst': 2121, 'Family Lawyer': 2112, 'Legal Secretary': 2110, 'Wedding Planner': 2103, 'Environmental Engineer': 2098, 'Network Technician': 2098, 'Database Developer': 2095, 'Back-End Developer': 2086, 'Process Engineer': 2086, 'Data Scientist': 2078, 'Financial Controller': 2066, 'Landscape Designer': 2057, 'Product Manager': 2053, 'Architectural Designer': 2050, 'QA Engineer': 1087, 'Market Analyst': 1085, 'Sales Associate': 1081, 'Event Manager': 1065, 'Key Account Manager': 1057, 'Investment Advisor': 1055, 'Product Designer': 1050, 'IT Administrator': 1050, 'Software Developer': 1048, 'HR Generalist': 1037, 'Network Analyst': 1031, 'Procurement Coordinator': 1031, 'Financial Planner': 1026, 'Personal Assistant': 1024, 'Inventory Analyst': 994, 'Supply Chain Analyst': 989})\n",
      "Resampled dataset shape: Counter({'Financial Controller': 14642, 'UI Developer': 14642, 'Research Analyst': 14642, 'Legal Advisor': 14642, 'Software Engineer': 14642, 'Digital Marketing Specialist': 14642, 'Human Resources Manager': 14642, 'Executive Assistant': 14642, 'Mechanical Designer': 14642, 'Back-End Developer': 14642, 'Systems Administrator': 14642, 'Chemical Analyst': 14642, 'Front-End Engineer': 14642, 'Pharmaceutical Sales Representative': 14642, 'Product Manager': 14642, 'Electrical Engineer': 14642, 'Substance Abuse Counselor': 14642, 'Event Coordinator': 14642, 'UX/UI Designer': 14642, 'Supply Chain Manager': 14642, 'Civil Engineer': 14642, 'Customer Support Specialist': 14642, 'Technical Writer': 14642, 'Physician Assistant': 14642, 'Business Development Manager': 14642, 'Marketing Specialist': 14642, 'Customer Success Manager': 14642, 'Procurement Specialist': 14642, 'Aerospace Engineer': 14642, 'Event Planner': 14642, 'Brand Ambassador': 14642, 'Veterinarian': 14642, 'Wedding Planner': 14642, 'Legal Secretary': 14642, 'Landscape Architect': 14642, 'Financial Advisor': 14642, 'Procurement Manager': 14642, 'Investment Analyst': 14642, 'Network Engineer': 14642, 'Litigation Attorney': 14642, 'Web Developer': 14642, 'Accountant': 14642, 'QA Analyst': 14642, 'Legal Assistant': 14642, 'Architect': 14642, 'Electrical Designer': 14642, 'Sales Manager': 14642, 'Financial Analyst': 14642, 'IT Support Specialist': 14642, 'IT Manager': 14642, 'Market Research Analyst': 14642, 'Business Analyst': 14642, 'Marketing Manager': 14642, 'Teacher': 14642, 'Graphic Designer': 14642, 'SEM Specialist': 14642, 'Account Manager': 14642, 'Project Manager': 14642, 'Office Manager': 14642, 'Software Tester': 14642, 'Customer Service Representative': 14642, 'Project Coordinator': 14642, 'Operations Manager': 14642, 'Software Developer': 14642, 'Mechanical Engineer': 14642, 'Legal Counsel': 14642, 'Database Developer': 14642, 'Network Analyst': 14642, 'Family Nurse Practitioner': 14642, 'Interior Designer': 14642, 'Data Scientist': 14642, 'Event Manager': 14642, 'Marketing Coordinator': 14642, 'Account Executive': 14642, 'Purchasing Agent': 14642, 'HR Manager': 14642, 'Nurse Practitioner': 14642, 'Sales Representative': 14642, 'Psychologist': 14642, 'Speech Therapist': 14642, 'SEO Specialist': 14642, 'Content Writer': 14642, 'Social Worker': 14642, 'Dental Hygienist': 14642, 'Administrative Assistant': 14642, 'Physical Therapist': 14642, 'Nurse Manager': 14642, 'Family Lawyer': 14642, 'HR Coordinator': 14642, 'Environmental Engineer': 14642, 'Research Scientist': 14642, 'Network Technician': 14642, 'Data Engineer': 14642, 'Public Relations Specialist': 14642, 'Chemical Engineer': 14642, 'Market Analyst': 14642, 'Art Director': 14642, 'HR Generalist': 14642, 'Architectural Designer': 14642, 'Network Security Specialist': 14642, 'Data Analyst': 14642, 'Marketing Analyst': 14642, 'Occupational Therapist': 14642, 'Database Administrator': 14642, 'Front-End Developer': 14642, 'Key Account Manager': 14642, 'Tax Consultant': 14642, 'Art Teacher': 14642, 'Account Director': 14642, 'Urban Planner': 14642, 'Financial Planner': 14642, 'QA Engineer': 14642, 'Structural Engineer': 14642, 'Brand Manager': 14642, 'Process Engineer': 14642, 'Supply Chain Analyst': 14642, 'Environmental Consultant': 14642, 'Java Developer': 14642, 'Sales Consultant': 14642, 'Quality Assurance Analyst': 14642, 'UX Researcher': 14642, 'Personal Assistant': 14642, 'Network Administrator': 14642, 'Social Media Coordinator': 14642, 'Web Designer': 14642, 'Landscape Designer': 14642, 'Social Media Manager': 14642, 'Finance Manager': 14642, 'Inventory Analyst': 14642, 'Product Designer': 14642, 'Investment Banker': 14642, 'Copywriter': 14642, 'Software Architect': 14642, 'Systems Engineer': 14642, 'Marketing Director': 14642, 'Data Entry Clerk': 14642, 'Systems Analyst': 14642, 'Paralegal': 14642, 'SEO Analyst': 14642, 'Procurement Coordinator': 14642, 'Email Marketing Specialist': 14642, 'Customer Service Manager': 14642, 'Pediatrician': 14642, 'Registered Nurse': 14642, 'IT Administrator': 14642, 'Investment Advisor': 14642, 'Sales Associate': 14642})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset shape: {Counter(y_train)}\")\n",
    "print(f\"Resampled dataset shape: {Counter(y_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_resampled.copy() \n",
    "y = y_train_resampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1937136, 67), (215238, 67), (1937136,), (215238,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1937136, 67), (215238, 67), (1937136, 147), (215238, 147))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:189: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  8704      \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  132096    \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  1049600   \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  2107400   \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  4229192   \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8878971 (33.87 MB)\n",
      "Trainable params: 8878971 (33.87 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.dense3 = Dense(1024, activation='relu')\n",
    "        self.dense4 = Dense(1024, activation='relu')\n",
    "        self.dense5 = Dense(2056, activation='relu')\n",
    "        self.dense6 = Dense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim = input_dim, num_classes = num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "757/757 [==============================] - 142s 188ms/step - loss: 4.9898 - accuracy: 0.0070 - val_loss: 4.9896 - val_accuracy: 0.0070\n",
      "Epoch 2/2\n",
      "757/757 [==============================] - 141s 187ms/step - loss: 4.9899 - accuracy: 0.0068 - val_loss: 4.9901 - val_accuracy: 0.0067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e3a1510e90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 2, validation_split=0.2, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobRecommendationSystem:\n",
    "    def __init__(self, data, cat_features, num_features, target_var):\n",
    "        self.data = data\n",
    "        self.cat_features = cat_features\n",
    "        self.num_features = num_features\n",
    "        self.target_var = target_var\n",
    "        self.encoder = OneHotEncoder(sparse = False)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.job_title_encoder = OneHotEncoder(sparse = False)\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        # Encode categorical features\n",
    "        encoded_features = self.encoder.fit_transform(self.data[self.cat_features])\n",
    "        encoded_df = pd.DataFrame(encoded_features, columns = self.encoder.get_feature_names_out())\n",
    "        \n",
    "        # Normalize numerical features\n",
    "        numerical_features = self.scaler.fit_transform(self.data[self.num_features])\n",
    "        numerical_df = pd.DataFrame(numerical_features, columns = self.num_features)\n",
    "        \n",
    "        # Flatten the skills list and encode\n",
    "        # The skills column must be list of list\n",
    "        all_skills = list(set(skill for sublist in self.data[\"skills\"] for skill in sublist))\n",
    "        skills_df = pd.DataFrame([[skill in sublist for skill in all_skills] for sublist in self.data[\"skills\"]], columns = all_skills)\n",
    "        \n",
    "        # Combine all features\n",
    "        self.X = pd.concat([encoded_df, numerical_df, skills_df], axis = 1)\n",
    "        \n",
    "        # Encode the Job Title\n",
    "        self.y = self.job_title_encoder.fit_transform(self.data[self.target_var])\n",
    "        \n",
    "        # Split the data into training and test sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define the neural network model using the Functional API\n",
    "        input_layer = Input(shape = (self.X_train.shape[1],))\n",
    "        dense_layer_1 = Dense(64, activation = \"relu\")(input_layer)\n",
    "        dense_layer_2 = Dense(32, activation = \"relu\")(dense_layer_1)\n",
    "        output_layer = Dense(self.y.shape[1], activation = \"softmax\")(dense_layer_2)\n",
    "        \n",
    "        self.model = Model(inputs = input_layer, outputs = output_layer)\n",
    "        self.model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    def train_model(self, epochs = 10, batch_size = 10):\n",
    "        self.model.fit(self.X_train, self.y_train, epochs = epochs, batch_size = batch_size, validation_split = 0.2)\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        loss, accuracy = self.model.evaluate(self.X_test, self.y_test)\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "    \n",
    "    def make_predictions(self):\n",
    "        predictions = self.model.predict(self.X_test)\n",
    "        predicted_classes = self.job_title_encoder.inverse_transform(predictions)\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data/data_after_feature_eng.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=[\"Job Title\"])\n",
    "y = dataset[\"Job Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((626410, 67), (69602, 67), (626410,), (69602,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadDense(Layer):\n",
    "\n",
    "  def __init__(self, units = 32, activation = None):\n",
    "    super(QuadDense, self).__init__()\n",
    "    self.units = units\n",
    "    self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    a_init = tf.random_normal_initializer()\n",
    "    b_init = tf.random_normal_initializer()\n",
    "    c_init = tf.zeros_initializer()\n",
    "\n",
    "    self.a = tf.Variable(initial_value = a_init(shape = (input_shape[-1], self.units),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"kernel\")\n",
    "\n",
    "    self.b = tf.Variable(initial_value = b_init(shape = (input_shape[-1], self.units),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"kernel\")\n",
    "\n",
    "    self.c = tf.Variable(initial_value = c_init(shape = (self.units, ),\n",
    "                                                dtype = \"float32\"),\n",
    "                         trainable = True,\n",
    "                         name = \"bias\")\n",
    "\n",
    "  def call(self, inputs):\n",
    "    result = tf.matmul(tf.math.square(inputs), self.a) + tf.matmul(inputs, self.b) + self.c\n",
    "\n",
    "    return self.activation(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            multiple                  8704      \n",
      "                                                                 \n",
      " dense_34 (Dense)            multiple                  132096    \n",
      "                                                                 \n",
      " dense_35 (Dense)            multiple                  1049600   \n",
      "                                                                 \n",
      " dense_36 (Dense)            multiple                  1049600   \n",
      "                                                                 \n",
      " dense_37 (Dense)            multiple                  2107400   \n",
      "                                                                 \n",
      " quad_dense_9 (QuadDense)    multiple                  8456328   \n",
      "                                                                 \n",
      " dense_38 (Dense)            multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13106107 (50.00 MB)\n",
      "Trainable params: 13106107 (50.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.dense3 = Dense(1024, activation='relu')\n",
    "        self.dense4 = Dense(1024, activation='relu')\n",
    "        self.dense5 = Dense(2056, activation='relu')\n",
    "        self.dense6 = QuadDense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim = input_dim, num_classes = num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "123/123 [==============================] - 63s 508ms/step - loss: 1676346.3750 - accuracy: 0.0183 - val_loss: 4.9550 - val_accuracy: 0.0299\n",
      "Epoch 2/5\n",
      "123/123 [==============================] - 63s 514ms/step - loss: 4.9021 - accuracy: 0.0300 - val_loss: 4.8859 - val_accuracy: 0.0299\n",
      "Epoch 3/5\n",
      "123/123 [==============================] - 64s 523ms/step - loss: 4.8844 - accuracy: 0.0300 - val_loss: 4.8846 - val_accuracy: 0.0299\n",
      "Epoch 4/5\n",
      "123/123 [==============================] - 62s 505ms/step - loss: 4.8838 - accuracy: 0.0300 - val_loss: 4.8844 - val_accuracy: 0.0299\n",
      "Epoch 5/5\n",
      "123/123 [==============================] - 61s 498ms/step - loss: 4.8835 - accuracy: 0.0300 - val_loss: 4.8842 - val_accuracy: 0.0299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e3bc700ad0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size = 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             multiple                  256       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           multiple                  24704     \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            multiple                  1097856   \n",
      "                                                                 \n",
      " batch_normalization (Batch  multiple                  512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  132096    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  multiple                  4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " attention (Attention)       multiple                  0         \n",
      "                                                                 \n",
      " attention_1 (Attention)     multiple                  0         \n",
      "                                                                 \n",
      " quad_dense_7 (QuadDense)    multiple                  2098176   \n",
      "                                                                 \n",
      " quad_dense_8 (QuadDense)    multiple                  2098176   \n",
      "                                                                 \n",
      " dense_30 (Dense)            multiple                  2107400   \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  multiple                  8224      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            multiple                  4229192   \n",
      "                                                                 \n",
      " dense_32 (Dense)            multiple                  302379    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12103067 (46.17 MB)\n",
      "Trainable params: 12096651 (46.15 MB)\n",
      "Non-trainable params: 6416 (25.06 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Conv1D, Flatten, BatchNormalization, Dropout, Attention, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a custom layer QuadDense\n",
    "class QuadDense(Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        super(QuadDense, self).__init__()\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        a_init = tf.random_normal_initializer()\n",
    "        b_init = tf.random_normal_initializer()\n",
    "        c_init = tf.zeros_initializer()\n",
    "\n",
    "        self.a = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=a_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"a\")\n",
    "\n",
    "        self.b = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer=b_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"b\")\n",
    "\n",
    "        self.c = self.add_weight(shape=(self.units,),\n",
    "                                 initializer=c_init,\n",
    "                                 trainable=True,\n",
    "                                 name=\"c\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        result = tf.matmul(tf.math.square(inputs), self.a) + tf.matmul(inputs, self.b) + self.c\n",
    "        return self.activation(result)\n",
    "\n",
    "# Define a model that uses various layers for better performance\n",
    "class MyModel(Model):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv1D(64, kernel_size=3, activation='relu', padding='same')\n",
    "        self.conv2 = Conv1D(128, kernel_size=3, activation='relu', padding='same')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.batch_norm1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.batch_norm2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.2)\n",
    "        \n",
    "        # Adding attention layers\n",
    "        self.attention1 = Attention()\n",
    "        self.attention2 = Attention()\n",
    "        \n",
    "        self.dense3 = QuadDense(1024, activation='relu')\n",
    "        self.dense4 = QuadDense(1024, activation='relu')\n",
    "        self.dense5 = Dense(2056, activation='relu')\n",
    "        self.batch_norm3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.2)\n",
    "        self.dense6 = Dense(2056, activation='relu')\n",
    "        self.output_layer = Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(tf.expand_dims(inputs, axis=-1))  # Expanding dims to use Conv1D\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Applying attention\n",
    "        query = tf.expand_dims(x, axis=1)  # Adding sequence dimension for Attention layer\n",
    "        attention_output1 = self.attention1([query, query])\n",
    "        x = Add()([x, tf.squeeze(attention_output1, axis=1)])\n",
    "        \n",
    "        attention_output2 = self.attention2([query, query])\n",
    "        x = Add()([x, tf.squeeze(attention_output2, axis=1)])\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense6(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Define the input dimension and number of classes\n",
    "input_dim = 67  # Example input dimension\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "# Build the model by providing an input shape\n",
    "model.build((None, input_dim))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "245/245 [==============================] - 97s 386ms/step - loss: 5.0009 - accuracy: 0.0262 - val_loss: 4.8959 - val_accuracy: 0.0299\n",
      "Epoch 2/5\n",
      "245/245 [==============================] - 94s 382ms/step - loss: 4.8910 - accuracy: 0.0298 - val_loss: 4.8892 - val_accuracy: 0.0297\n",
      "Epoch 3/5\n",
      "245/245 [==============================] - 90s 367ms/step - loss: 4.8879 - accuracy: 0.0299 - val_loss: 7.2791 - val_accuracy: 0.0064\n",
      "Epoch 4/5\n",
      "245/245 [==============================] - 90s 368ms/step - loss: 4.8857 - accuracy: 0.0300 - val_loss: 4.8851 - val_accuracy: 0.0299\n",
      "Epoch 5/5\n",
      "245/245 [==============================] - 90s 368ms/step - loss: 4.8847 - accuracy: 0.0300 - val_loss: 4.8849 - val_accuracy: 0.0299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e39ffe3a90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 5, validation_split=0.2, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Model:\n",
    "    def __init__(self, input_dim, hidden_layers, output_dim):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        input_dim (int): Number of the input features\n",
    "        hidden_layers (list): list of the number of units in the hidden layer\n",
    "        output_dim: nNumber of the output units \n",
    "        \"\"\"\n",
    "        self.model = Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        self.model.add(Dense(hidden_layers[0], input_dim = input_dim, activation = \"relu\"))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for units in hidden_layers[1:]:\n",
    "            self.model.add(Dense(units, activation = \"relu\"))\n",
    "        \n",
    "        # Output layer\n",
    "        self.model.add(Dense(output_dim, activation = \"linear\"))\n",
    "        \n",
    "        # Compile the model\n",
    "        self.model.compile(optimizer = \"adam\", loss = \"mse\", metrics = [\"mse\"])\n",
    "    \n",
    "    def train(self, X_train, y_train, epochs = 10, batch_size = 32):\n",
    "        self.model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
